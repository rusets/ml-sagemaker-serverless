# üß† SageMaker Serverless Demo (Mobilenet V2)

![Terraform](https://img.shields.io/badge/IaC-Terraform-7B42BC?logo=terraform&logoColor=white)
![AWS](https://img.shields.io/badge/Cloud-AWS-FF9900?logo=amazonaws&logoColor=white)
![Python](https://img.shields.io/badge/Language-Python-3776AB?logo=python&logoColor=white)
![Serverless](https://img.shields.io/badge/Architecture-Serverless-FF4F00?logo=awslambda&logoColor=white)
![SageMaker](https://img.shields.io/badge/AI-SageMaker-232F3E?logo=amazonaws&logoColor=white)

---

### üåê Live Demo
- **Website:** [https://ml-demo.store/](https://ml-demo.store/)
- **API Endpoint:** [`/predict`](https://222izyufsl.execute-api.us-east-1.amazonaws.com/predict)
- **Model:** Mobilenet V2 (Image Classification)

---

## üìã Overview

This project demonstrates an **end-to-end serverless image classification pipeline** on AWS.  
It uses **Amazon SageMaker Serverless Inference** to host the pre-trained **Mobilenet V2** model, integrated with **API Gateway**, **Lambda**, and a **static web UI** deployed via **S3 + CloudFront** ‚Äî all provisioned automatically with **Terraform**.

The goal is to show how to deploy a **production-ready ML inference system** that‚Äôs fast, scalable, and cost-efficient ‚Äî perfect for portfolios, demos, or internal proof-of-concept setups.

<p align="center">
  <img src="frontend/thomas.png" alt="Demo Screenshot" width="600"/>
</p>

---

## üèóÔ∏è Architecture (high-level)

```mermaid
flowchart LR
  %% Node styles
  classDef svc fill:#f8f9ff,stroke:#6366f1,stroke-width:1.5,rx:10,ry:10,color:#111827
  classDef ext fill:#fff7ed,stroke:#fb923c,stroke-width:1.5,rx:10,ry:10,color:#111827
  classDef iac fill:#eef2ff,stroke:#7c3aed,stroke-width:1.5,rx:10,ry:10,color:#111827
  classDef data fill:#ecfdf5,stroke:#10b981,stroke-width:1.5,rx:10,ry:10,color:#111827

  %% Frontend
  user((User / Browser)):::ext --> cf["Amazon CloudFront"]:::svc
  cf --> s3["Amazon S3<br/>Static site + config.js"]:::data

  %% API Layer
  cf --> apigw["Amazon API Gateway<br/>HTTP API"]:::svc
  apigw --> lam["AWS Lambda<br/>Inference Proxy"]:::svc
  lam --> sm["Amazon SageMaker<br/>Serverless Endpoint<br/>Mobilenet V2"]:::svc
  sm -->|JSON Response| user

  %% IaC & CI/CD
  subgraph IaC_CICD [Infrastructure as Code / CI-CD]
    gh["GitHub Actions"]:::ext --> tf["Terraform"]:::iac
  end
  tf -.-> s3
  tf -.-> cf
  tf -.-> apigw
  tf -.-> lam
  tf -.-> sm
```

---

## ‚öôÔ∏è How It Works

1Ô∏è‚É£ **User** opens the static web UI (`index.html` + `script.js`) served via **CloudFront + S3**.  
2Ô∏è‚É£ `config.js` contains the API URL (no-cache headers).  
3Ô∏è‚É£ The browser sends an image URL to `POST /predict` on **API Gateway**.  
4Ô∏è‚É£ **Lambda (inference proxy)** receives the request and invokes the **SageMaker Serverless Endpoint**.  
5Ô∏è‚É£ **SageMaker** runs inference using the **Mobilenet V2** model.  
6Ô∏è‚É£ The **predicted class and probability** are returned as a JSON response to the UI.

---

## üöÄ Deployment (Terraform)

**Prerequisites**
- AWS CLI configured
- Terraform ‚â• 1.5
- A pre-trained `model.tar.gz` (Mobilenet V2) in the `infra/` directory

```bash
cd infra
terraform init
terraform apply -auto-approve
```

The comments for the commands above are intentionally placed below the block per your style preference.

Terraform provisions:
- IAM roles for Lambda and SageMaker  
- S3 bucket + CloudFront distribution  
- API Gateway (HTTP API) and Lambda integration  
- SageMaker model + endpoint (serverless)  
- Uploads `config.js` and invalidates CloudFront cache

---

## üí∞ Cost Optimization

| Service | Optimization | Description |
|----------|---------------|-------------|
| **SageMaker** | Serverless Endpoint | Pay only for invocation time |
| **Lambda** | On-demand | Scales automatically with traffic |
| **CloudFront** | CDN caching | Reduces S3 GETs and latency |
| **S3** | Static site | Extremely low-cost hosting |
| **API Gateway** | HTTP API | Cheaper and faster than REST |
| **Terraform** | Destroy when idle | Clean teardown stops billing |

üí° *Tip:* Ideal for demos or learning ‚Äî infrastructure can be fully destroyed with one command when not in use.

---

## üîÆ Future Improvements

- Automated **CI/CD** via GitHub Actions (plan/apply workflows)  
- **Cognito** authentication for `/predict` requests  
- **CloudWatch dashboards** for real-time metrics  
- **Multi-model endpoint** deployment pattern  
- Optional **SVG diagram** for ultra-sharp zoom in docs

---

## üß∞ Tech Stack

| Category | Technology |
|-----------|-------------|
| **Infrastructure** | AWS (SageMaker, Lambda, API Gateway, S3, CloudFront, IAM) |
| **IaC** | Terraform |
| **CI/CD** | GitHub Actions |
| **Language** | Python 3.10 (Lambda + inference) |
| **Frontend** | HTML, CSS, JavaScript |
| **Model** | Mobilenet V2 (Image classification) |

---

## üìÇ Folder Structure

```
ml-sagemaker-serverless/
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ index.html
‚îÇ   ‚îú‚îÄ‚îÄ out.json
‚îÇ   ‚îú‚îÄ‚îÄ script.js
‚îÇ   ‚îú‚îÄ‚îÄ style.css
‚îÇ   ‚îî‚îÄ‚îÄ thomas.png
‚îú‚îÄ‚îÄ infra/
‚îÇ   ‚îú‚îÄ‚îÄ api_and_config.tf
‚îÇ   ‚îú‚îÄ‚îÄ existing.tf
‚îÇ   ‚îú‚îÄ‚îÄ iam_lambda_invoke.tf
‚îÇ   ‚îú‚îÄ‚îÄ minimal.auto.tfvars
‚îÇ   ‚îú‚îÄ‚îÄ model.tar.gz
‚îÇ   ‚îú‚îÄ‚îÄ outputs.tf
‚îÇ   ‚îú‚îÄ‚îÄ providers.tf
‚îÇ   ‚îú‚îÄ‚îÄ sagemaker_deploy.tf
‚îÇ   ‚îú‚îÄ‚îÄ terraform.tfstate
‚îÇ   ‚îú‚îÄ‚îÄ terraform.tfstate.backup
‚îÇ   ‚îî‚îÄ‚îÄ variables.tf
‚îú‚îÄ‚îÄ mobilenet_sls/
‚îÇ   ‚îî‚îÄ‚îÄ code/
‚îÇ       ‚îú‚îÄ‚îÄ inference.py
‚îÇ       ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ inference_proxy.py
‚îî‚îÄ‚îÄ terraform.tfstate
```

---

## üßπ Cleanup

```bash
cd infra
terraform destroy -auto-approve
```

The comment for the command above is intentionally placed below the block per your style preference.

---

## ü™™ License

MIT ‚Äî Free to use, modify, and deploy for demos, learning, or portfolio purposes.

---

> üí° **Project purpose:** Showcase how to deploy a real ML model using AWS Serverless architecture with Terraform automation.  
> Ideal for DevOps and Cloud Engineer portfolios.
