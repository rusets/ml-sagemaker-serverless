# ML SageMaker Serverless â€” Mobilenet V2 Demo

This project demonstrates a **fully automated AWS ML inference pipeline** using Terraform and GitHub Actions.  
It deploys a PyTorch-based MobileNetV2 image classifier on **AWS SageMaker Serverless**, fronted by an **API Gateway + Lambda proxy**, and served through a static **CloudFront + S3 website**.

---

## ğŸ—ï¸ Architecture (High-Level)

```mermaid
graph TD
  A[User uploads image<br>via browser] --> B[S3 static website<br>(ml-demo.store)]
  B --> C[API Gateway<br>HTTP POST /predict]
  C --> D[Lambda Proxy<br>(Python 3.12)]
  D --> E[SageMaker Serverless<br>Endpoint (MobileNetV2)]
  E --> D
  D --> C
  C --> B
  B --> A
  subgraph AWS Infrastructure
  B
  C
  D
  E
  end
```

---

## ğŸ“ Project Structure

```plaintext
.
â”œâ”€â”€ frontend
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ script.js
â”‚   â”œâ”€â”€ style.css
â”‚   â””â”€â”€ thomas.png
â”œâ”€â”€ infra
â”‚   â”œâ”€â”€ api_and_config.tf
â”‚   â”œâ”€â”€ existing.tf
â”‚   â”œâ”€â”€ iam_lambda_invoke.tf
â”‚   â”œâ”€â”€ minimal.auto.tfvars
â”‚   â”œâ”€â”€ model.tar.gz
â”‚   â”œâ”€â”€ outputs.tf
â”‚   â”œâ”€â”€ providers.tf
â”‚   â”œâ”€â”€ sagemaker_deploy.tf
â”‚   â””â”€â”€ variables.tf
â”œâ”€â”€ mobilenet_sls
â”‚   â””â”€â”€ code
â”‚       â”œâ”€â”€ inference.py
â”‚       â””â”€â”€ requirements.txt
â”œâ”€â”€ scripts
â”‚   â””â”€â”€ inference_proxy.py
â””â”€â”€ README.md
```

---

## âš™ï¸ Core Components

- **Frontend** â€” simple static website hosted on S3 + CloudFront (`https://ml-demo.store/`).
- **Lambda Proxy** â€” lightweight Python function to relay API calls to SageMaker.
- **SageMaker Endpoint** â€” serverless inference model (`mobilenet-v2-sls`).
- **API Gateway** â€” HTTP API v2 used for `/predict` route.
- **Terraform IaC** â€” manages entire stack reproducibly.
- **GitHub Actions (CI/CD)** â€” deploys and updates automatically.

---

## ğŸ”’ Security & IAM

This project follows AWS security best practices:

- **KMS (Key Management Service):**
  - The Lambda update process (`lambda_kms_clear`) safely clears and reapplies encryption keys during redeploys.
  - Environment variables are reset in controlled sequence to avoid stale or mismatched KMS bindings.

- **IAM Roles:**
  - **SageMaker Execution Role** (`*-sagemaker-exec`) â€” minimal permissions to pull containers from ECR and read model artifacts from S3.
  - **Lambda Execution Role** (`*-lambda-exec`) â€” includes only one inline policy: `sagemaker:InvokeEndpoint` for a specific SageMaker endpoint ARN.
  - **GitHub OIDC Role** â€” short-lived access for CI/CD without long-term AWS credentials.

This strict IAM separation and dynamic KMS handling ensures secure, auditable deployments.

---

## ğŸ’° Cost Optimization

- **SageMaker Serverless** â€” billed per inference request (no cost when idle).
- **Lambda + API Gateway** â€” minimal usage-based pricing, automatically scaled to zero.
- **S3 + CloudFront** â€” Free Tier friendly; assets cached globally.
- **Model artifact (~14 MB)** â€” stored once in S3; versioned by timestamp.
- **Automatic sleep/wake pattern** â€” SageMaker endpoints incur no hourly cost between invocations.

Average monthly cost (for a small demo): **under $1.50/month**.

---

## ğŸŒ Live Demo

**Website:** [ml-demo.store](https://ml-demo.store/)  
**API Endpoint:** [https://222izyufsl.execute-api.us-east-1.amazonaws.com/predict](https://222izyufsl.execute-api.us-east-1.amazonaws.com/predict)  
**GitHub Repo:** [github.com/rusets/ml-sagemaker-serverless](https://github.com/rusets/ml-sagemaker-serverless)

---

## ğŸ§© Tech Stack

**AWS:** SageMaker, Lambda, API Gateway, CloudFront, S3, IAM, KMS  
**Infra:** Terraform (v1.6+), AWS Provider (v5.50+)  
**Model:** MobileNetV2 (PyTorch, ImageNet pre-trained)  
**Frontend:** HTML / CSS / JS â€” lightweight and responsive

---

## ğŸ“œ License

MIT Â© 2025 Ruslan Dashkin
