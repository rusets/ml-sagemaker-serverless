# ğŸš€ SageMaker Serverless Demo --- Mobilenet V2 (Endâ€‘toâ€‘End Production Stack)

![Terraform](https://img.shields.io/badge/IaC-Terraform-7B42BC?logo=terraform&logoColor=white)
![AWS](https://img.shields.io/badge/Cloud-AWS-FF9900?logo=amazonaws&logoColor=white)
![Python](https://img.shields.io/badge/Language-Python-3776AB?logo=python&logoColor=white)
![Serverless](https://img.shields.io/badge/Architecture-Serverless-FF4F00?logo=awslambda&logoColor=white)
![SageMaker](https://img.shields.io/badge/SageMaker-Serverless-0073BB?logo=amazonaws&logoColor=white)
![CI/CD](https://img.shields.io/badge/CI%2FCD-GitHub%20Actions-2088FF?logo=githubactions&logoColor=white)
![Security](https://img.shields.io/badge/Security-IAM%20%7C%20KMS-2F4F4F?logo=amazonaws&logoColor=white)

------------------------------------------------------------------------

## ğŸŒ Live Demo

-   **Website:** https://ml-demo.store
   
------------------------------------------------------------------------

## ğŸ“‹ Overview

A fully automated, production-style **serverless ML application** built
on AWS.\
The system performs **image classification** using **Mobilenet V2
(ImageNet)** deployed on **Amazon SageMaker Serverless Inference**,
wrapped with **API Gateway + Lambda**, served through **S3 +
CloudFront**, and fully provisioned via **Terraform**.

This project demonstrates:

-   Zero-server ML inference
-   Realistic production wiring across AWS services
-   Proper IAM, least privilege, encryption, and remote Terraform state
-   Clean frontend â†’ backend â†’ ML pipeline\
-   Fast, deterministic deployments

------------------------------------------------------------------------

## ğŸ—ï¸ Architecture (High-Level)

``` mermaid
flowchart LR
  U["User / Browser"] --> CF["Amazon CloudFront"]
  CF --> S3["Amazon S3<br/>Static site + config.js"]
  CF --> APIGW["Amazon API Gateway<br/>HTTP API /predict"]
  APIGW --> LBD["AWS Lambda<br/>Proxy Python 3.12"]
  LBD --> SM["Amazon SageMaker<br/>Serverless Endpoint<br/>Mobilenet V2"]
  SM -->|"Top-5 JSON"| U

  subgraph IaC_Terraform [IaC / Terraform]
    TF["Terraform"]
  end
  TF -.-> CF
  TF -.-> S3
  TF -.-> APIGW
  TF -.-> LBD
  TF -.-> SM
```

------------------------------------------------------------------------

## âš™ï¸ Components

### **Frontend (S3 + CloudFront)**

-   Static web UI (HTML/CSS/JS)\
-   Drag-and-drop uploader\
-   `config.js` regenerated by Terraform\
-   CloudFront invalidation only where needed

### **API (API Gateway HTTP API)**

-   Simpler & cheaper than REST API\
-   Single route â†’ `POST /predict`\
-   CORS enabled

### **Lambda Proxy (Python 3.12)**

-   Thin orchestrator\
-   Decodes body (Base64), forwards to SageMaker Runtime\
-   Handles CORS & JSON marshalling\
-   Minimal latency design

### **SageMaker Serverless Endpoint**

-   Mobilenet V2, ImageNet pre-trained\
-   CPU, low-cost, pay-per-request\
-   Automatically scales\
-   2048 MB memory / concurrency 1 (tunable)

### **Terraform IaC**

-   Complete endâ€‘toâ€‘end provisioning\
-   Remote state (S3 + DynamoDB locks)\
-   Role wiring, permissions, CloudFront invalidations\
-   Null resources orchestrate SageMaker lifecycle

------------------------------------------------------------------------

## ğŸ“ Project Structure

    .
    â”œâ”€â”€ frontend/
    â”‚   â”œâ”€â”€ index.html
    â”‚   â”œâ”€â”€ script.js
    â”‚   â”œâ”€â”€ style.css
    â”‚   â””â”€â”€ thomas.png
    â”œâ”€â”€ infra/
    â”‚   â”œâ”€â”€ api_and_config.tf
    â”‚   â”œâ”€â”€ backend.tf
    â”‚   â”œâ”€â”€ existing.tf
    â”‚   â”œâ”€â”€ iam_lambda_invoke.tf
    â”‚   â”œâ”€â”€ minimal.auto.tfvars
    â”‚   â”œâ”€â”€ outputs.tf
    â”‚   â”œâ”€â”€ providers.tf
    â”‚   â”œâ”€â”€ sagemaker_deploy.tf
    â”‚   â””â”€â”€ variables.tf
    â”œâ”€â”€ mobilenet_sls/
    â”‚   â””â”€â”€ code/
    â”‚       â”œâ”€â”€ inference.py
    â”‚       â””â”€â”€ requirements.txt
    â”œâ”€â”€ scripts/
    â”‚   â””â”€â”€ inference_proxy.py
    â””â”€â”€ README.md

------------------------------------------------------------------------

# ğŸ¯ Why This Project Is Valuable for Interviews

### **1. Demonstrates real production-level architecture**

This is a complete end-to-end ML service with clean separation between the frontend, API layer, and inference logic.
It shows that you can design and operate a genuine cloud-native system â€” not just run experiments inside SageMaker notebooks.

### **2. Shows strong AWS integration skills**

CloudFront â†’ S3 â†’ API Gateway â†’ Lambda â†’ SageMaker â†’ IAM â†’ Terraform.
Correctly wiring these services together is non-trivial, and this project demonstrates practical understanding of how AWS components interact in real environments.

### **3. Modern serverless ML design**

It uses a fully serverless, low-maintenance, pay-per-request architecture.
This is exactly how companies deploy lightweight ML models in real production systems today.

### **4. Strong Infrastructure-as-Code discipline**

Everything is reproducible.
No manual AWS clicks.
Remote state + DynamoDB locking.
Clear resource dependencies and predictable deploys.
This signals reliability and readiness for team-scale infrastructure work.

### **5. Reflects real engineering problem-solving**

Cold starts
CORS behavior
CloudFront caching
IAM permission failures
SageMaker endpoint update states
â€”all of these are real industry problems, and the project shows that you can diagnose and solve them correctly.

### **6. Signals full-stack ownership**

You built the UI, backend API, ML runtime, CI/CD, Terraform infrastructure, IAM boundaries, and the overall system design.
This demonstrates the ability to take responsibility for an entire vertical slice of a production application.

### **7. Creates strong opportunities for technical discussion**

This project naturally invites conversations about latency, scaling characteristics, caching strategies, cost optimization, observability, and architectural trade-offs â€” all topics interviewers use to assess engineering depth.

------------------------------------------------------------------------

# ğŸ“˜ Lessons Learned

### 1) IAM is simple until it breaks

You solved APIGW â†’ Lambda permissions, Lambda â†’ SageMaker invoke,
SageMaker â†’ ECR.

### 2) Serverless ML is about orchestration, not models

Endpoint states, rollbacks, timestamped configs --- handled perfectly.

### 3) CloudFront is always aggressively cached

You learned invalidation strategy.

### 4) Lambda should stay thin

You moved inference to SageMaker --- correct decision.

### 5) Terraform requires structure

You enforced consistent headers, naming, and separated IAM, data
sources, SM logic.

### 6) Integration is harder than ML

Base64 decoding, JSON body, content types, error handling.

### 7) Stability comes from anticipating edge cases

You handled "Failed", "Updating", "Missing", and "InService" logic.

### 8) Endâ€‘toâ€‘end ownership is your strongest skill

This project proves it.

------------------------------------------------------------------------

# ğŸ§ª Troubleshooting --- Problems & How They Were Solved

### **Problem: API Gateway returned 403 / 500**

**Fix:** Missing IAM permission for Lambda â†’ added exact ARN-based
`InvokeEndpoint`.

------------------------------------------------------------------------

### **Problem: Lambda cannot call SageMaker endpoint**

**Fix:** Wrong exec role name extraction â†’ added role parsing logic via
`split("/")`.

------------------------------------------------------------------------

### **Problem: CloudFront kept serving old config.js**

**Fix:** Added automatic invalidation in Terraform after config update.

------------------------------------------------------------------------

### **Problem: Endpoint stuck in "Updating" or "Failed"**

**Fix:** Created robust state machine in Bash:\
- If Failed â†’ delete & recreate\
- If Creating/Updating â†’ wait\
- If Missing â†’ create\
- Finally: wait until InService

------------------------------------------------------------------------

### **Problem: CORS errors in the browser**

**Fix:** Added correct headers in Lambda `_resp()`.

------------------------------------------------------------------------

### **Problem: Terraform drift from existing resources**

**Fix:** Added data sources + consistent naming + removed duplicate IAM
resources.

------------------------------------------------------------------------

# ğŸ› ï¸ Deployment

``` bash
cd infra
terraform init
terraform apply -auto-approve
```

Destroy:

``` bash
terraform destroy -auto-approve
```

------------------------------------------------------------------------

# ğŸ’° Cost Optimization

-   Serverless pay-per-ms\
-   Lambda lightweight, no heavy dependencies\
-   HTTP API (cheaper than REST API)\
-   CloudFront long TTL except config.js\
-   Small model artifact\
-   Minimal concurrency

Realâ€‘world cost: **\~\$1--1.5/month**.

------------------------------------------------------------------------

# ğŸ”® Future Work (What I Would Improve Next)

### **1) Add CI/CD (GitHub Actions â†’ OIDC â†’ Terraform Apply)**

Full automation for PR â†’ plan â†’ approve â†’ apply.

### **2) Add autoscaling policies for endpoint**

Dynamic memory / concurrency tuning.

### **3) Add S3 versioned model registry**

Better lineage + rollback support.

### **4) Add CloudWatch Alarms**

-   Lambda errors\
-   Endpoint invocation failures\
-   Latency spikes

### **5) Add custom domain for API Gateway**

Better UX + easier integration.

### **6) Add WebSocket for real-time inference logs**

For advanced observability.

------------------------------------------------------------------------

# â“ FAQ

### **Why SageMaker Serverless instead of Lambda-only inference?**

Faster, cheaper, supports large models, avoids timeouts.

### **Why keep Lambda at all?**

To decouple API Gateway from ML layer and manage CORS/security cleanly.

### **Why Mobilenet?**

Lightweight, ImageNet, perfect for demos.\
You can drop in any PyTorch model instead.

### **Why timestamp configs/models?**

Prevent conflicts, allow rollbacks, ensure deterministic updates.

### **Is this production-ready?**

Yes --- with CI/CD, alarms, auth, and private endpoints it becomes a
full production footprint.

------------------------------------------------------------------------

## ğŸ“¸ Screenshots

Below are a few focused screenshots illustrating the core parts of the project.

---
### **UI â€” Initial State (Before Upload)**

Landing view of the frontend before selecting or dropping an image.

![UI Empty](docs/screenshots/ui_empty.png)

---

### **UI â€” Prediction Result**

Shows the full end-to-end workflow:  
Image uploaded â†’ API Gateway â†’ Lambda proxy â†’ SageMaker Serverless â†’ Top-5 predictions.

![UI Prediction](docs/screenshots/ui_prediction.png)

---

### **SageMaker Endpoint â€” InService (CLI)**

Demonstrates that the SageMaker Serverless endpoint is healthy and serving traffic.  
All sensitive values are redacted.

![SageMaker InService](docs/screenshots/sagemaker_inservice.png)

---

### **Terraform â€” Successful Apply**

Shows that the entire infrastructure is synchronized and no drift is detected.  
API URLs and IDs are masked so the screenshot is safe to publish.

![Terraform Apply](docs/screenshots/terraform_apply.png)

# ğŸ“œ License

- Released under the **MIT License** â€” free to use, modify, and learn from.
- Â© Ruslan Dashkin (â€œğŸš€ Ruslan AWSâ€).
- The â€œğŸš€ Ruslan AWSâ€ branding and all related visuals are protected; commercial reuse or rebranding is prohibited without permission.