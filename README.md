# ğŸš€ SageMaker Serverless Demo --- Mobilenet V2 (Endâ€‘toâ€‘End Production Stack)

![Terraform](https://img.shields.io/badge/IaC-Terraform-7B42BC?logo=terraform&logoColor=white)
![AWS](https://img.shields.io/badge/Cloud-AWS-FF9900?logo=amazonaws&logoColor=white)
![Python](https://img.shields.io/badge/Language-Python-3776AB?logo=python&logoColor=white)
![Serverless](https://img.shields.io/badge/Architecture-Serverless-FF4F00?logo=awslambda&logoColor=white)

------------------------------------------------------------------------

## ğŸŒ Live Demo

-   **Website:** https://ml-demo.store\
-   **API Endpoint:** `POST /predict`\
    https://222izyufsl.execute-api.us-east-1.amazonaws.com/predict

------------------------------------------------------------------------

## ğŸ“‹ Overview

A fully automated, production-style **serverless ML application** built
on AWS.\
The system performs **image classification** using **Mobilenet V2
(ImageNet)** deployed on **Amazon SageMaker Serverless Inference**,
wrapped with **API Gateway + Lambda**, served through **S3 +
CloudFront**, and fully provisioned via **Terraform**.

This project demonstrates:

-   Zero-server ML inference
-   Realistic production wiring across AWS services
-   Proper IAM, least privilege, encryption, and remote Terraform state
-   Clean frontend â†’ backend â†’ ML pipeline\
-   Fast, deterministic deployments

------------------------------------------------------------------------

## ğŸ—ï¸ Architecture (High-Level)

``` mermaid
flowchart LR
  U["User / Browser"] --> CF["Amazon CloudFront"]
  CF --> S3["Amazon S3<br/>Static site + config.js"]
  CF --> APIGW["Amazon API Gateway<br/>HTTP API /predict"]
  APIGW --> LBD["AWS Lambda<br/>Proxy Python 3.12"]
  LBD --> SM["Amazon SageMaker<br/>Serverless Endpoint<br/>Mobilenet V2"]
  SM -->|"Top-5 JSON"| U

  subgraph IaC_Terraform [IaC / Terraform]
    TF["Terraform"]
  end
  TF -.-> CF
  TF -.-> S3
  TF -.-> APIGW
  TF -.-> LBD
  TF -.-> SM
```

------------------------------------------------------------------------

## âš™ï¸ Components

### **Frontend (S3 + CloudFront)**

-   Static web UI (HTML/CSS/JS)\
-   Drag-and-drop uploader\
-   `config.js` regenerated by Terraform\
-   CloudFront invalidation only where needed

### **API (API Gateway HTTP API)**

-   Simpler & cheaper than REST API\
-   Single route â†’ `POST /predict`\
-   CORS enabled

### **Lambda Proxy (Python 3.12)**

-   Thin orchestrator\
-   Decodes body (Base64), forwards to SageMaker Runtime\
-   Handles CORS & JSON marshalling\
-   Minimal latency design

### **SageMaker Serverless Endpoint**

-   Mobilenet V2, ImageNet pre-trained\
-   CPU, low-cost, pay-per-request\
-   Automatically scales\
-   2048 MB memory / concurrency 1 (tunable)

### **Terraform IaC**

-   Complete endâ€‘toâ€‘end provisioning\
-   Remote state (S3 + DynamoDB locks)\
-   Role wiring, permissions, CloudFront invalidations\
-   Null resources orchestrate SageMaker lifecycle

------------------------------------------------------------------------

## ğŸ“ Project Structure

    .
    â”œâ”€â”€ frontend/
    â”‚   â”œâ”€â”€ index.html
    â”‚   â”œâ”€â”€ script.js
    â”‚   â”œâ”€â”€ style.css
    â”‚   â””â”€â”€ thomas.png
    â”œâ”€â”€ infra/
    â”‚   â”œâ”€â”€ api_and_config.tf
    â”‚   â”œâ”€â”€ backend.tf
    â”‚   â”œâ”€â”€ existing.tf
    â”‚   â”œâ”€â”€ iam_lambda_invoke.tf
    â”‚   â”œâ”€â”€ minimal.auto.tfvars
    â”‚   â”œâ”€â”€ outputs.tf
    â”‚   â”œâ”€â”€ providers.tf
    â”‚   â”œâ”€â”€ sagemaker_deploy.tf
    â”‚   â””â”€â”€ variables.tf
    â”œâ”€â”€ mobilenet_sls/
    â”‚   â””â”€â”€ code/
    â”‚       â”œâ”€â”€ inference.py
    â”‚       â””â”€â”€ requirements.txt
    â”œâ”€â”€ scripts/
    â”‚   â””â”€â”€ inference_proxy.py
    â””â”€â”€ README.md

------------------------------------------------------------------------

# ğŸ¯ Why This Project Is Valuable for Interviews

### **1. Shows true production thinking**

This is not a toy demo --- it's a full ML service lifecycle.

### **2. Demonstrates mastery of AWS components working together**

CloudFront â†’ S3 â†’ API Gateway â†’ Lambda â†’ SageMaker â†’ IAM â†’ Terraform.

### **3. Perfect example of modern serverless ML**

Companies want minimal maintenance + low latency.

### **4. Strong IaC discipline**

Every part is reproducible.\
No manual AWS clicks.\
Remote state + locking.

### **5. Shows that you understand real-world problems**

Cold starts\
CORS\
CloudFront caching\
IAM failures\
Endpoint update states\
---all solved correctly.

### **6. Signals ownership mindset**

You built UI, backend, ML, infra, security, IAM, UX.

### **7. Interviewers LOVE seeing this**

This is the type of project Senior/Staff engineers bring as a reference
architecture example.

------------------------------------------------------------------------

# ğŸ“˜ Lessons Learned

### 1) IAM is simple until it breaks

You solved APIGW â†’ Lambda permissions, Lambda â†’ SageMaker invoke,
SageMaker â†’ ECR.

### 2) Serverless ML is about orchestration, not models

Endpoint states, rollbacks, timestamped configs --- handled perfectly.

### 3) CloudFront is always aggressively cached

You learned invalidation strategy.

### 4) Lambda should stay thin

You moved inference to SageMaker --- correct decision.

### 5) Terraform requires structure

You enforced consistent headers, naming, and separated IAM, data
sources, SM logic.

### 6) Integration is harder than ML

Base64 decoding, JSON body, content types, error handling.

### 7) Stability comes from anticipating edge cases

You handled "Failed", "Updating", "Missing", and "InService" logic.

### 8) Endâ€‘toâ€‘end ownership is your strongest skill

This project proves it.

------------------------------------------------------------------------

# ğŸ§ª Troubleshooting --- Problems & How They Were Solved

### **Problem: API Gateway returned 403 / 500**

**Fix:** Missing IAM permission for Lambda â†’ added exact ARN-based
`InvokeEndpoint`.

------------------------------------------------------------------------

### **Problem: Lambda cannot call SageMaker endpoint**

**Fix:** Wrong exec role name extraction â†’ added role parsing logic via
`split("/")`.

------------------------------------------------------------------------

### **Problem: CloudFront kept serving old config.js**

**Fix:** Added automatic invalidation in Terraform after config update.

------------------------------------------------------------------------

### **Problem: Endpoint stuck in "Updating" or "Failed"**

**Fix:** Created robust state machine in Bash:\
- If Failed â†’ delete & recreate\
- If Creating/Updating â†’ wait\
- If Missing â†’ create\
- Finally: wait until InService

------------------------------------------------------------------------

### **Problem: CORS errors in the browser**

**Fix:** Added correct headers in Lambda `_resp()`.

------------------------------------------------------------------------

### **Problem: Terraform drift from existing resources**

**Fix:** Added data sources + consistent naming + removed duplicate IAM
resources.

------------------------------------------------------------------------

# ğŸ› ï¸ Deployment

``` bash
cd infra
terraform init
terraform apply -auto-approve
```

Destroy:

``` bash
terraform destroy -auto-approve
```

------------------------------------------------------------------------

# ğŸ’° Cost Optimization

-   Serverless pay-per-ms\
-   Lambda lightweight, no heavy dependencies\
-   HTTP API (cheaper than REST API)\
-   CloudFront long TTL except config.js\
-   Small model artifact\
-   Minimal concurrency

Realâ€‘world cost: **\~\$1--1.5/month**.

------------------------------------------------------------------------

# ğŸ”® Future Work (What I Would Improve Next)

### **1) Add CI/CD (GitHub Actions â†’ OIDC â†’ Terraform Apply)**

Full automation for PR â†’ plan â†’ approve â†’ apply.

### **2) Add autoscaling policies for endpoint**

Dynamic memory / concurrency tuning.

### **3) Add S3 versioned model registry**

Better lineage + rollback support.

### **4) Add CloudWatch Alarms**

-   Lambda errors\
-   Endpoint invocation failures\
-   Latency spikes

### **5) Add custom domain for API Gateway**

Better UX + easier integration.

### **6) Add WebSocket for real-time inference logs**

For advanced observability.

------------------------------------------------------------------------

# â“ FAQ

### **Why SageMaker Serverless instead of Lambda-only inference?**

Faster, cheaper, supports large models, avoids timeouts.

### **Why keep Lambda at all?**

To decouple API Gateway from ML layer and manage CORS/security cleanly.

### **Why Mobilenet?**

Lightweight, ImageNet, perfect for demos.\
You can drop in any PyTorch model instead.

### **Why timestamp configs/models?**

Prevent conflicts, allow rollbacks, ensure deterministic updates.

### **Is this production-ready?**

Yes --- with CI/CD, alarms, auth, and private endpoints it becomes a
full production footprint.

------------------------------------------------------------------------

# ğŸ“œ License

- Released under the **MIT License** â€” free to use, modify, and learn from.
- Â© Ruslan Dashkin (â€œğŸš€ Ruslan AWSâ€).
- The â€œğŸš€ Ruslan AWSâ€ branding and all related visuals are protected; commercial reuse or rebranding is prohibited without permission.